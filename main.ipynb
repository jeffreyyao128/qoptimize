{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8-yYZglGODU",
    "outputId": "6a9ebd71-7435-4a97-db10-5f2fcf195af3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "import jax\n",
    "from jax import jit,vmap,grad\n",
    "from jax import random\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import vjp\n",
    "from qutip import *\n",
    "from jax.experimental import ode,optimizers\n",
    "\n",
    "N = 4 # set number of qubits as a global parameter\n",
    "N1 = 10 #fourier series size\n",
    "key = random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1cKxLXnVGODZ"
   },
   "outputs": [],
   "source": [
    "@vmap\n",
    "def normalize(psi):\n",
    "    '''\n",
    "    Normalize a given wavefunction\n",
    "    '''\n",
    "    return psi/jnp.linalg.norm(psi)\n",
    "\n",
    "def generate_batch(U,key,batch_size=100,*args):\n",
    "    '''\n",
    "    To generate a bach of data point given a unitary gate\n",
    "    '''\n",
    "    psi_batch = random.normal(key,shape=(2**N,batch_size)) + 1j*random.normal(key,shape=(2**N,batch_size))\n",
    "    psi0_batch = U@psi_batch\n",
    "    #      initial psi          training data psi0\n",
    "    return normalize(psi_batch), normalize(psi0_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPSCTqnOGODc"
   },
   "source": [
    "To perceed neural network, an ODE solver is needed. In our case is `scipy.integrate.solve_ivp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gyjrFww7GODc"
   },
   "outputs": [],
   "source": [
    "def forward(t1,psi0,flat_p,method='matrix'):\n",
    "    '''\n",
    "    solver for Schrodinger equation with initial condition of psi0 and Hamiltonian in the interval of [0,t1]\n",
    "    use mathod of scipy\n",
    "    '''\n",
    "    if method == 'function':\n",
    "        Hz = lambda t,x: -1j*H(t,x,flat_p,t1)\n",
    "    elif method == 'matrix':\n",
    "        Hz = lambda t,x: -1j*Hmat(t,x,flat_p,t1)\n",
    "    else:\n",
    "        raise NameError(\"wrong solver\")\n",
    "    \n",
    "    sol = solve_ivp(Hz,[0,t1],psi0,t_eval=[0,t1])\n",
    "    return sol.y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J649wAPpGODf"
   },
   "outputs": [],
   "source": [
    "def initial(key1 = None):\n",
    "    '''\n",
    "    Return randomized parameters\n",
    "    '''\n",
    "    if (key1).all() == None:\n",
    "        return np.random.normal(size=(N1*(N+1)+1,))\n",
    "    else:\n",
    "        return random.normal(key1,shape=(N1*(N+1)+1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QVz6THRdGODj"
   },
   "outputs": [],
   "source": [
    "def n(i,x):\n",
    "    '''\n",
    "    number operator for n_i (x)\n",
    "    '''\n",
    "    return (x&2**i)/2**i\n",
    "\n",
    "def unpackp(x):\n",
    "    return jnp.array(x[:N1]) , jnp.array([x[(i+1)*N1:(i+2)*N1] for i in range(N)]), jnp.array(x[-1], dtype=jnp.float32)\n",
    "\n",
    "def flatten(x):\n",
    "    return 0 # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPT96vU6ZZ4r"
   },
   "source": [
    "Our Hamiltonian is $$\\begin{aligned}\n",
    "\\frac{H}{\\hbar}=& \\frac{\\Omega(t)}{2} \\sum_{i=1}^{N} \\sigma_{x}^{(i)}-\\sum_{i=1}^{N} \\Delta_{i}(t) n_{i} \\\\\n",
    "&+\\sum_{i<j} \\frac{V}{|i-j|^{6}} n_{i} n_{j}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zBCGwRkgGODl"
   },
   "outputs": [],
   "source": [
    "def H(t,psi,flat_p,t1):\n",
    "    '''\n",
    "    Using xor to implement off diagonal element\n",
    "    '''\n",
    "    D, = jnp.shape(psi)\n",
    "    res = jnp.zeros(D,dtype=jnp.complex64)\n",
    "\n",
    "    w = 2*jnp.pi/t1\n",
    "\n",
    "    u_omega, u_d, V = unpackp(flat_p)\n",
    "    omega = jnp.sum(jnp.array([u_omega[i]*jnp.sin(w*(i+1)*t) for i in range(N1)]))\n",
    "    delta = [jnp.sum(jnp.array([u_d[j,i]*jnp.sin(w*(i+1)*t) for i in range(N1)])) for j in range(N)]\n",
    "    \n",
    "    for x in range(D):\n",
    "        Ci = psi[x]\n",
    "        diag = - jnp.sum(jnp.array([ delta[i]*n(i,x) for i in range(N)]))\\\n",
    "        + jnp.sum(jnp.array([[V*n(i,x)*n(j,x)/jnp.abs(i-j)**6 if i<j else 0 for i in range(N)] for j in range(N)])) #diagonal part of hamiltonian\n",
    "        res = jax.ops.index_add(res, (x,), diag*Ci)\n",
    "        cast = jnp.array([x^2**i for i in range(N)]) # ^ is for xor, to calculate the flip operation\n",
    "        res = jax.ops.index_add(res, cast, omega*Ci/2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For speed we use dense matrix to represent Hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "n0 = jnp.array([jnp.diag(jnp.array([n(i,x) for x in range(2**N)])) for i in range(N)]) #number operator matrix form n0[i] = n_i\n",
    "\n",
    "print(n0.shape)\n",
    "#print(jnp.matmul(n0[1],n0[2]))\n",
    "\n",
    "def H_independent():\n",
    "    '''\n",
    "    Time independent part of Hamiltonian\n",
    "    '''\n",
    "    res = jnp.zeros((2**N,2**N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if j<= i: continue\n",
    "            params = 1/np.abs(i-j)**6\n",
    "            res += params*(jnp.dot(n0[i],n0[j]))\n",
    "    return res\n",
    "H1 = H_independent()\n",
    "# print(jnp.trace(H1))\n",
    "\n",
    "f = lambda x,y,i : 1 if y==x^2**i else 0\n",
    "H2 = sum([jnp.array([[f(x,y,i) for x in range(2**N)] for y in range(2**N)]) for i in range(N)]) #checked\n",
    "\n",
    "def Hmat(t,psi,flat_p,t1):\n",
    "    '''\n",
    "    Using dense matrix to represent Hamiltonian\n",
    "    '''\n",
    "    D, = jnp.shape(psi)\n",
    "    res = jnp.zeros(D,dtype=jnp.complex64)\n",
    "    \n",
    "    w = 2*jnp.pi/t1\n",
    "    \n",
    "    u_omega, u_d, V = unpackp(flat_p)\n",
    "    \n",
    "    ft =jnp.array([jnp.sin(w*(i+1)*t) for i in range(N1)])\n",
    "\n",
    "    omega = jnp.dot(u_omega,ft)\n",
    "    delta = u_d@ft\n",
    "    \n",
    "    return (V*H1 + 0.5* omega* H2 - jnp.einsum('i,ijk->jk',delta,n0))@psi\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Voa8tv0HGODo"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def loss(psi,flat_p,t1,A,psi0):\n",
    "    '''\n",
    "    define the loss function, which is a pure function\n",
    "    '''\n",
    "    omega = 2*jnp.pi/t1\n",
    "    l1 = 1 - jnp.abs(jnp.dot(jnp.conjugate(psi),psi0))**2 # Overlap\n",
    "    \n",
    "    u_omega, u_d, V = unpackp(flat_p)\n",
    "    freqeuncy = jnp.array([i*omega**2 for i in range(N1)])\n",
    "    l2 = 0.5*jnp.dot(jnp.conjugate(freqeuncy),u_omega**2)\n",
    "#     l2 = 0.5*jnp.sum(jnp.array([ (i*omega*flat_p[i])**2 for i in range(N1)]))\n",
    "    l3 = 0.5*jnp.sum(jnp.dot(u_d**2,jnp.conjugate(freqeuncy)))\n",
    "#     l3 = 0.5*jnp.sum(jnp.array([ (i*omega*flat_p[i+N1])**2 for i in range(N1)]))\n",
    "    l4 = 0.5*V**2\n",
    "    \n",
    "    return A[0]*l1+A[1]*l2+A[2]*l3+A[3]*l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ak3mbk0YGODq"
   },
   "outputs": [],
   "source": [
    "def grad_all(psi1,psi0,flat_p,t1,A,method='matrix'):\n",
    "    '''\n",
    "    gradient with adjoint method\n",
    "    return value and grad\n",
    "    '''\n",
    "    if method=='matrix':\n",
    "        H_evol = Hmat\n",
    "    elif method == 'function':\n",
    "        H_evol = H\n",
    "    else:\n",
    "        raise NameError('Wrong dynamics')\n",
    "        \n",
    "    D, = jnp.shape(psi1)\n",
    "    \n",
    "    loss_val, a0 = jax.value_and_grad(loss, argnums=0)(psi1,flat_p,t1,A,psi0)\n",
    "\n",
    "    pLt1 = jnp.array([jnp.dot(a0,H_evol(t1,psi1,flat_p,t1))])\n",
    "    \n",
    "    aug_state = jnp.concatenate([psi1, a0, -pLt1, jnp.zeros(((N+1)*N1+1,))])\n",
    "    print(aug_state.shape)\n",
    "    def unpack(x):\n",
    "              # z , vjp_z   , vjp_t , vjp_args\n",
    "        return x[:D], x[D:2*D], x[2*D], x[2*D+1:]\n",
    "    \n",
    "    def wrap_vjp(augment_state,t,parameters):\n",
    "        Hz = lambda z : H_evol(t,z,parameters,t1)\n",
    "        Ht = lambda t0 : H_evol(t0,augment_state[0],parameters,t1)\n",
    "        Hp = lambda p : H_evol(t,augment_state[0],p,t1)\n",
    "        _, vjp_funz = vjp(Hz, augment_state[0])\n",
    "        _, vjp_funt = vjp(Ht, t)\n",
    "        _, vjp_funp = vjp(Hp, flat_p)\n",
    "        \n",
    "        # vjp_funz(augment_state[1]) is a tuple\n",
    "#         print(vjp_funz(augment_state[1])[0].shape,vjp_funp(augment_state[1])[0].shape,vjp_funt(augment_state[1])[0].shape)\n",
    "        return [- vjp_funz(augment_state[1])[0],- vjp_funp(augment_state[1])[0],- vjp_funt(augment_state[1])[0]]\n",
    "    \n",
    "    def aug_dynamics(t,augment_state,*args):\n",
    "        parameters, = args\n",
    "        unpacked_aug_state = unpack(augment_state)\n",
    "\n",
    "        vjps = wrap_vjp(unpacked_aug_state,t,parameters)\n",
    "        aug_grad = jnp.concatenate([H_evol(t,unpacked_aug_state[0],parameters,t1), vjps[0], vjps[1], jnp.array([vjps[2]])])\n",
    "\n",
    "        return aug_grad\n",
    "\n",
    "    aug_state0 = solve_ivp(aug_dynamics,[t1,0],aug_state,t_eval=[t1,0],args=(flat_p,)) # Couldn't use jit for this, since it has no fixed memory.\n",
    "    return loss_val, aug_state0.y[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJSUd71THAQq"
   },
   "source": [
    "Our Hamiltonian is \n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{H}{\\hbar}=& \\frac{\\Omega(t)}{2} \\sum_{i=1}^{N} \\sigma_{x}^{(i)}-\\sum_{i=1}^{N} \\Delta_{i}(t) n_{i} \\\\\n",
    "&+\\sum_{i<j} \\frac{V}{|i-j|^{6}} n_{i} n_{j}\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tSyOBEQjtKyS"
   },
   "outputs": [],
   "source": [
    "def check_with_qutip(psi0,flat_p,t1):\n",
    "    q_psi = Qobj(psi0,dims=[[2,2,2,2], [1 ,1,1,1]])\n",
    "\n",
    "    t = np.linspace(0,t1,100)\n",
    "    w = 2*jnp.pi/t1\n",
    "\n",
    "    u_omega, u_d, V = unpackp(flat_p)\n",
    "    \n",
    "    ft = lambda t: jnp.array([jnp.sin(w*(i+1)*t) for i in range(N1)])\n",
    "    omega = lambda t,args: jnp.dot(u_omega,ft(t))\n",
    "    delta = lambda t,args: -u_d@ft(t)\n",
    "    delta_func = [lambda t,args: delta(t,args)[i] for i in range(N1)]\n",
    "#     omega = lambda t,args : jnp.sum(jnp.array([u_omega[i]*jnp.sin(w*(i+1)*t) for i in range(N1)]))\n",
    "#     delta_func = [lambda t,args : - jnp.sum(jnp.array([u_d[j,i]*jnp.sin(w*(i+1)*t) for i in range(N1)])) for j in range(N)]\n",
    "    h = []\n",
    "\n",
    "    si = qeye(2)\n",
    "    sx = sigmax()\n",
    "    sy = sigmay()\n",
    "    sz = sigmaz()\n",
    "    ni = num(2)\n",
    "    # time independent part\n",
    "    h_list = []\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if j<= i: continue\n",
    "            param = V/np.abs(i-j)**6\n",
    "            op_list=[si for _ in range(N)]\n",
    "            op_list[i] = ni\n",
    "            op_list[j] = ni\n",
    "            h_list.append(param*tensor(op_list))\n",
    "    H0 = sum(h_list)\n",
    "#     print(H0.tr()/V)\n",
    "    h.append(H0)\n",
    "    \n",
    "    #time dependent part\n",
    "    sx_list = []\n",
    "\n",
    "    for n in range(N):\n",
    "        op_list = []\n",
    "        for m in range(N):\n",
    "            op_list.append(si)\n",
    "\n",
    "        op_list[n] = sx\n",
    "        sx_list.append(tensor(op_list))\n",
    "\n",
    "    # construct the hamiltonian\n",
    "    H1 = sum([0.5 * sx_list[n] for n in range(N)])\n",
    "    h.append([H1,omega])\n",
    "\n",
    "    for i in range(N):\n",
    "        n_list = [si for _ in range(N)]\n",
    "        n_list[i] = ni\n",
    "        H2= tensor(n_list)\n",
    "        h.append([H2,delta_func[i]])\n",
    "    output = mesolve(h, q_psi, t, progress_bar = True)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_optimize(data_batch,Loss_vector,flat_params,t1,learning_rate=1,mass=1,num_steps=5):\n",
    "    '''\n",
    "    Train the neural ode over a given databatch\n",
    "    '''\n",
    "    psi_batch,psi0_batch = data_batch # we try with single wavefunction for instance\n",
    "    \n",
    "    D,batch_size = jnp.shape(psi_batch)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        psi,psi0 = psi_batch[:,i],psi0_batch[:,i]\n",
    "        aug_params = jnp.concatenate([jnp.array([t1]),flat_params])\n",
    "        L = aug_params.size\n",
    "        opt_init, opt_update, get_params = optimizers.momentum(learning_rate,mass)\n",
    "        opt_state = opt_init(aug_params)\n",
    "\n",
    "        def unpack(x):\n",
    "                  # t , args\n",
    "            return x[0], x[1:]\n",
    "\n",
    "        def step_fun(step, opt_state,psi,psi0):\n",
    "    #         value, grads = jax.value_and_grad(loss_fn)(get_params(opt_state))\n",
    "            aug_params = get_params(opt_state)\n",
    "            \n",
    "            t1,flat_params = unpack(aug_params)\n",
    "            print(t1)\n",
    "            res = forward(t1,psi,flat_params,method='matrix')\n",
    "            print('forward mode completed')\n",
    "            value, grads = grad_all(res,psi0,flat_params,t1,Loss_vector)\n",
    "            \n",
    "            opt_state = opt_update(step, jnp.real(grads[-L:]), opt_state)\n",
    "            return value, opt_state\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            value, opt_state = step_fun(step, opt_state,psi,psi0)\n",
    "            print('step {0}: loss is {1}'.format(step,value))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_gate_U = tensor([sigmax(),sigmax(),sigmax(),sigmax()]).full() # Take \\otimes simga_z^i as test unitary gate\n",
    "# print(Test_gate_U.full())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cpfn-q-UGODt",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    keypsi, keyinit = random.split(key)\n",
    "    t1 = 2\n",
    "    Loss_vector = [1,0.1,0.1,0.1]\n",
    "    flat_params = initial(keyinit)\n",
    "\n",
    "    # a = jnp.concatenate([jnp.array([t1]),flat_params])\n",
    "    data_batch= generate_batch(Test_gate_U,keypsi,batch_size=1)\n",
    "    q_optimize(data_batch,Loss_vector,flat_params,t1,learning_rate=1,mass=1,num_steps=5)\n",
    "#     keypsi, keyinit = random.split(key)\n",
    "#     t1 = 2\n",
    "#     Loss_vector = [1,0.1,0.1,0.1]\n",
    "#     psi,psi0 = generate_batch(Test_gate_U,keypsi,batch_size=1)\n",
    "#     flat_params = initial(keyinit)\n",
    "#     %time res = forward(t1,psi[:,0],flat_params,method='matrix')\n",
    "#     print(res.shape,psi0[:,0].shape)\n",
    "#     res0 = check_with_qutip(np.array(psi0),flat_params, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.73 s, sys: 782 ms, total: 5.51 s\n",
      "Wall time: 5.53 s\n",
      "(84,)\n",
      "CPU times: user 6min 42s, sys: 55.2 s, total: 7min 37s\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "psi,psi0 = generate_batch(Test_gate_U,keypsi,batch_size=1)\n",
    "t1 =10\n",
    "%time res = forward(t1,psi[:,0],flat_params,method='matrix')\n",
    "%time loss_val, gd = grad_all(res,psi0[:,0],flat_params,t1,Loss_vector)  # grad_all(psi1,flat_p,t1,A,psi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 235 ms, total: 1.68 s\n",
      "Wall time: 1.68 s\n",
      "(84,)\n",
      "CPU times: user 16.2 s, sys: 2.28 s, total: 18.4 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "psi,psi0 = generate_batch(Test_gate_U,keypsi,batch_size=1)\n",
    "t1 =2\n",
    "%time res = forward(t1,psi[:,0],flat_params,method='matrix')\n",
    "%time loss_val, gd = grad_all(res,psi0[:,0],flat_params,t1,Loss_vector)  # grad_all(psi1,flat_p,t1,A,psi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
